{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# MOL-MOE for Caco-2 Permeability Prediction\n",
    "\n",
    "This notebook trains separate MOL-MOE models for:\n",
    "1. **Caco-2 Permeability Papp A>B** (regression)\n",
    "2. **Caco-2 Permeability Efflux** (regression)\n",
    "\n",
    "**Dataset Info:**\n",
    "- Papp A>B: 2,157 molecules (range: 0-51.41)\n",
    "- Efflux: 2,161 molecules (range: 0.26-105.64)\n",
    "\n",
    "**Architecture:**\n",
    "- 12 experts total (4 SMI-TED + 4 SELFIES-TED + 4 MHG-GNN)\n",
    "- k=4 experts activated per sample\n",
    "- Single-task regression approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jzg3123sonk",
   "metadata": {},
   "source": "## 0. RunPod Setup (Auto-Configuration)\n\nThis section automatically configures the environment for RunPod/Jupyter instances:\n- Detects platform and GPU availability\n- Installs `uv` package manager for fast dependency installation  \n- Installs PyTorch 2.2.0 with CUDA 11.8 and all required packages\n- Configures paths dynamically (no hardcoded paths)\n\n**First run:** ~3-5 minutes for package installation\n**Subsequent runs:** ~10-30 seconds (packages cached by uv)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t79ubgoaxjq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP CELL 1: Environment Detection & Path Configuration\n",
    "# ============================================================\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect environment\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "IS_JUPYTER = 'ipykernel' in sys.modules\n",
    "DEVICE_NAME = 'GPU' if os.system('nvidia-smi > /dev/null 2>&1') == 0 else 'CPU'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ENVIRONMENT DETECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Platform: {platform.system()}\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"Runtime: {'Colab' if IS_COLAB else 'Jupyter' if IS_JUPYTER else 'Unknown'}\")\n",
    "print(f\"Device: {DEVICE_NAME}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define base paths using pathlib for cross-platform compatibility\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "MATERIALS_ROOT = NOTEBOOK_DIR.parent.parent.parent  # From notebooks/ up to materials/\n",
    "MOL_MOE_ROOT = NOTEBOOK_DIR.parent  # models/mol_moe/\n",
    "EXPERTS_DIR = MOL_MOE_ROOT / \"experts\"\n",
    "MOE_DIR = MOL_MOE_ROOT / \"moe\"\n",
    "DATA_DIR = MATERIALS_ROOT  # CSVs are at materials/ level\n",
    "\n",
    "print(f\"\\nPath Configuration:\")\n",
    "print(f\"  Notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"  Materials root: {MATERIALS_ROOT}\")\n",
    "print(f\"  MoE root: {MOL_MOE_ROOT}\")\n",
    "print(f\"  Data directory: {DATA_DIR}\")\n",
    "\n",
    "# Verify critical paths exist\n",
    "assert MATERIALS_ROOT.exists(), f\"Materials root not found: {MATERIALS_ROOT}\"\n",
    "assert EXPERTS_DIR.exists(), f\"Experts directory not found: {EXPERTS_DIR}\"\n",
    "assert MOE_DIR.exists(), f\"MoE directory not found: {MOE_DIR}\"\n",
    "assert DATA_DIR.exists(), f\"Data directory not found: {DATA_DIR}\"\n",
    "\n",
    "print(\"\\n✓ All critical paths verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51slff3o8vg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP CELL 2: UV Installation & Verification\n",
    "# ============================================================\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "def check_uv():\n",
    "    \"\"\"Check if uv is installed and install if necessary\"\"\"\n",
    "    uv_path = shutil.which('uv')\n",
    "    if uv_path:\n",
    "        result = subprocess.run(['uv', '--version'], capture_output=True, text=True)\n",
    "        print(f\"✓ uv found: {result.stdout.strip()}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "if not check_uv():\n",
    "    print(\"Installing uv...\")\n",
    "    # Install uv using the official installer\n",
    "    subprocess.run([\n",
    "        sys.executable, '-m', 'pip', 'install', '--quiet', 'uv'\n",
    "    ], check=True)\n",
    "    \n",
    "    if check_uv():\n",
    "        print(\"✓ uv installed successfully\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Failed to install uv\")\n",
    "else:\n",
    "    print(\"uv already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "w0ls8vn1wnk",
   "source": "# ============================================================\n# SETUP CELL 2.5: Install System Dependencies (Linux only)\n# ============================================================\nimport platform\n\nif platform.system() == 'Linux':\n    print(\"Installing system dependencies for RDKit...\")\n    try:\n        # Install X11 libraries needed for RDKit rendering\n        result = subprocess.run([\n            'apt-get', 'update', '-qq'\n        ], capture_output=True, text=True)\n        \n        subprocess.run([\n            'apt-get', 'install', '-y', '-qq',\n            'libxrender1',\n            'libxext6',\n            'libsm6',\n            'libfontconfig1'\n        ], check=True, capture_output=True, text=True)\n        \n        print(\"✓ System dependencies installed\")\n    except subprocess.CalledProcessError as e:\n        print(\"⚠️  Warning: Could not install system packages (may need sudo)\")\n        print(\"   RDKit rendering may not work, but training will still function\")\n    except FileNotFoundError:\n        print(\"⚠️  Warning: apt-get not found (not a Debian/Ubuntu system)\")\n        print(\"   RDKit rendering may not work, but training will still function\")\nelse:\n    print(f\"Platform: {platform.system()} - skipping Linux system dependencies\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "riemm7gn75",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# SETUP CELL 3: Install Dependencies with UV\n# ============================================================\n\nprint(\"Installing dependencies with uv (this may take a few minutes on first run)...\")\nprint(\"Configuration:\")\nprint(\"  - Python: 3.10+\")\nprint(\"  - PyTorch: 2.2.0 with CUDA 11.8\")\nprint(\"  - Installing to: system environment\")\nprint()\n\ntry:\n    # Step 1: Install PyTorch with CUDA 11.8\n    print(\"[1/3] Installing PyTorch with CUDA 11.8...\")\n    subprocess.run([\n        'uv', 'pip', 'install',\n        '--python', sys.executable,\n        '--index-url', 'https://download.pytorch.org/whl/cu118',\n        'torch==2.2.0',\n        'torchvision==0.17.0', \n        'torchaudio==2.2.0'\n    ], check=True, capture_output=True)\n    print(\"      ✓ PyTorch 2.2.0 with CUDA 11.8 installed\")\n    \n    # Step 2: Install torch-scatter with special index\n    print(\"[2/3] Installing torch-scatter...\")\n    subprocess.run([\n        'uv', 'pip', 'install',\n        '--python', sys.executable,\n        '--find-links', 'https://data.pyg.org/whl/torch-2.2.0+cu118.html',\n        'torch-scatter'\n    ], check=True, capture_output=True)\n    print(\"      ✓ torch-scatter installed\")\n    \n    # Step 3: Install remaining dependencies\n    print(\"[3/3] Installing remaining dependencies...\")\n    remaining_deps = [\n        'torch-geometric>=2.3.1',\n        'matplotlib==3.9.2',\n        'numpy>=1.26.1,<2.0.0',\n        'pandas>=1.5.3',\n        'scikit-learn>=1.5.0',\n        'rdkit>=2024.3.5',\n        'datasets>=2.13.1',\n        'huggingface-hub',\n        'transformers>=4.38',\n        'selfies>=2.1.0',\n        'tqdm>=4.66.4',\n        'xgboost==2.0.0',\n        'seaborn',  # For plotting\n    ]\n    \n    subprocess.run([\n        'uv', 'pip', 'install',\n        '--python', sys.executable,\n    ] + remaining_deps, check=True, capture_output=True)\n    print(\"      ✓ All dependencies installed successfully\")\n    \nexcept subprocess.CalledProcessError as e:\n    print(f\"\\n❌ Installation failed: {e}\")\n    print(\"Trying to show error output:\")\n    if e.stderr:\n        print(e.stderr.decode())\n    raise\n\n# Verify installations\nimport torch\nprint(f\"\\nVerification:\")\nprint(f\"  PyTorch version: {torch.__version__}\")\nprint(f\"  CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"  CUDA version: {torch.version.cuda}\")\n    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n    \nprint(\"\\n\" + \"=\"*60)\nprint(\"✓ Environment setup complete!\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wjobsjrkqyc",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# SETUP CELL 4: Configure Module Import Paths\n# ============================================================\n\n# Add project directories to Python path\n# Use absolute paths to avoid issues with working directory changes\nsys.path.insert(0, str(MOL_MOE_ROOT))  # For 'from moe import ...'\nsys.path.insert(0, str(EXPERTS_DIR))   # For 'from mhg_model import ...' (needed for unpickling)\nsys.path.insert(0, str(MOE_DIR))       # For 'from models import ...'\n\nprint(\"Module search paths configured:\")\nfor i, path in enumerate(sys.path[:6]):\n    print(f\"  {i}: {path}\")\n\n# Verify imports work\ntry:\n    from moe import MoE\n    print(\"\\n✓ MoE module importable\")\nexcept ImportError as e:\n    print(f\"\\n✗ MoE import failed: {e}\")\n    print(\"  Ensure you're running from materials/models/mol_moe/notebooks/\")\n    \ntry:\n    from models import Net\n    print(\"✓ Net model importable\")\nexcept ImportError as e:\n    print(f\"✗ Net import failed: {e}\")\n\n# Test that mhg_model can be imported (needed for unpickling)\ntry:\n    import mhg_model\n    print(\"✓ mhg_model module importable (needed for model loading)\")\nexcept ImportError as e:\n    print(f\"⚠️  mhg_model not directly importable: {e}\")\n    print(\"   This may cause issues when loading pre-trained MHG-GNN model\")\n\nprint(\"\\n✓ Module paths configured successfully\")\nprint(\"\\n\" + \"=\"*60)\nprint(\"SETUP COMPLETE - Ready to proceed with training!\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "# System\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Deep learning\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom moe import MoE, train\nfrom models import Net\n\n# Machine learning\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Data\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Chemistry\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors\n\n# Try to enable PandasTools rendering (may fail on headless systems)\ntry:\n    from rdkit.Chem import PandasTools\n    PandasTools.RenderImagesInAllDataFrames(True)\n    print(\"✓ RDKit rendering enabled\")\nexcept ImportError as e:\n    print(f\"⚠️  RDKit rendering disabled (missing system libraries)\")\n    print(\"   Training will work normally, but molecule images won't display in DataFrames\")\n    PandasTools = None\n\ndef normalize_smiles(smi, canonical=True, isomeric=False):\n    try:\n        normalized = Chem.MolToSmiles(\n            Chem.MolFromSmiles(smi), canonical=canonical, isomericSmiles=isomeric\n        )\n    except:\n        normalized = None\n    return normalized\n\ntorch.manual_seed(42)\nnp.random.seed(42)\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {DEVICE}\")"
  },
  {
   "cell_type": "markdown",
   "id": "load-models",
   "metadata": {},
   "source": [
    "## 2. Load Foundation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-selfies",
   "metadata": {},
   "outputs": [],
   "source": "from experts.selfies_ted.load import SELFIES\n\nprint(\"Loading SELFIES-TED...\")\nmodel_selfies = SELFIES()\nmodel_selfies.load()\n\n# Fix 1: Patch get_embedding to move tensors to device\noriginal_get_embedding = model_selfies.get_embedding\n\ndef patched_get_embedding(self, selfies):\n    \"\"\"Patched get_embedding that ensures tensors are on the correct device\"\"\"\n    encoding = self.tokenizer(selfies['selfies'], return_tensors='pt', padding=True, truncation=True)\n    \n    # Move to same device as the model\n    device = next(self.model.parameters()).device\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    outputs = self.model.encoder(input_ids=input_ids, attention_mask=attention_mask)\n    model_output = outputs.last_hidden_state\n    \n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(model_output.size()).float()\n    sum_embeddings = torch.sum(model_output * input_mask_expanded, 1)\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    mean_embeddings = sum_embeddings / sum_mask\n    \n    # Move back to CPU for dataset processing\n    embeddings = {'embedding': mean_embeddings.detach().cpu().numpy().tolist()}\n    return embeddings\n\nmodel_selfies.get_embedding = lambda selfies: patched_get_embedding(model_selfies, selfies)\n\n# Fix 2: Patch encode to disable multiprocessing\noriginal_encode = model_selfies.encode\n\ndef patched_encode(self, smiles_list, use_gpu=False, return_tensor=True):\n    \"\"\"Patched encode that disables multiprocessing and ensures device compatibility\"\"\"\n    import pandas as pd\n    import numpy as np\n    from datasets import Dataset\n    \n    # Convert to SELFIES\n    selfies = []\n    self.invalid = []\n    for i, smile in enumerate(smiles_list):\n        try:\n            selfies.append(self.encoder(smile))\n        except:\n            selfies.append(\"\")\n            self.invalid.append(i)\n    \n    selfies_df = pd.DataFrame(selfies, columns=[\"selfies\"])\n    data = Dataset.from_pandas(selfies_df)\n    \n    # CRITICAL: num_proc=None to disable multiprocessing (prevents CUDA fork issues)\n    embedding = data.map(self.get_embedding, batched=True, num_proc=None, batch_size=128)\n    \n    # Convert Column to numpy array (datasets returns Column objects)\n    emb = np.array(list(embedding[\"embedding\"]))\n    \n    for idx in self.invalid:\n        emb = np.insert(emb, idx, np.zeros(emb.shape[1]), axis=0)\n    \n    if return_tensor:\n        return torch.tensor(emb)\n    return emb\n\nmodel_selfies.encode = lambda smiles_list, use_gpu=False, return_tensor=True: patched_encode(\n    model_selfies, smiles_list, use_gpu, return_tensor\n)\n\nprint(\"✓ SELFIES-TED loaded\")\nprint(\"  - Multiprocessing disabled (CUDA compatibility)\")\nprint(\"  - Device handling patched\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-mhg",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experts.mhg_model.load import load\n",
    "\n",
    "print(\"Loading MHG-GNN...\")\n",
    "mhg_gnn = load()\n",
    "print(\"✓ MHG-GNN loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-smited",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experts.smi_ted_light.load import load_smi_ted, MolTranBertTokenizer\n",
    "\n",
    "print(\"Loading SMI-TED...\")\n",
    "smi_ted = load_smi_ted()\n",
    "print(\"✓ SMI-TED loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-section",
   "metadata": {},
   "source": [
    "## 3. Select Target Endpoint\n",
    "\n",
    "**Choose which endpoint to train:**\n",
    "- `papp_ab`: Caco-2 Permeability Papp A>B\n",
    "- `efflux`: Caco-2 Permeability Efflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-endpoint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELECT YOUR ENDPOINT HERE\n",
    "# ============================================\n",
    "ENDPOINT = 'papp_ab'  # Options: 'papp_ab' or 'efflux'\n",
    "# ============================================\n",
    "\n",
    "# Use dynamic paths computed in setup cells\n",
    "if ENDPOINT == 'papp_ab':\n",
    "    data_file = DATA_DIR / 'train_Caco2_Permeability_Papp_AB.csv'\n",
    "    target_col = 'Caco-2 Permeability Papp A>B'\n",
    "    model_name = 'Caco2_Papp_AB'\n",
    "elif ENDPOINT == 'efflux':\n",
    "    data_file = DATA_DIR / 'train_Caco2_Permeability_Efflux.csv'\n",
    "    target_col = 'Caco-2 Permeability Efflux'\n",
    "    model_name = 'Caco2_Efflux'\n",
    "else:\n",
    "    raise ValueError(\"ENDPOINT must be 'papp_ab' or 'efflux'\")\n",
    "\n",
    "# Verify data file exists\n",
    "assert data_file.exists(), f\"Data file not found: {data_file}\"\n",
    "\n",
    "print(f\"Selected endpoint: {ENDPOINT}\")\n",
    "print(f\"Target column: {target_col}\")\n",
    "print(f\"Model name: {model_name}\")\n",
    "print(f\"Data file: {data_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "## 4. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(data_file)\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize-smiles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize SMILES\n",
    "print(\"Normalizing SMILES...\")\n",
    "df['canon_smiles'] = df['SMILES'].apply(normalize_smiles)\n",
    "\n",
    "# Remove invalid SMILES\n",
    "original_count = len(df)\n",
    "df = df.dropna(subset=['canon_smiles', target_col])\n",
    "print(f\"Removed {original_count - len(df)} invalid entries\")\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "\n",
    "# Show target statistics\n",
    "print(f\"\\n{target_col} statistics:\")\n",
    "print(df[target_col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df[target_col], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel(target_col)\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title(f'Distribution of {target_col}')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df[target_col])\n",
    "axes[1].set_ylabel(target_col)\n",
    "axes[1].set_title(f'Box Plot of {target_col}')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 70% train, 15% validation, 15% test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(valid_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "\n",
    "# Prepare data\n",
    "smiles_col = 'canon_smiles'\n",
    "\n",
    "X_train = train_df[smiles_col].to_list()\n",
    "y_train = torch.tensor(train_df[target_col].values, dtype=torch.float32)\n",
    "\n",
    "X_valid = valid_df[smiles_col].to_list()\n",
    "y_valid = torch.tensor(valid_df[target_col].values, dtype=torch.float32)\n",
    "\n",
    "X_test = test_df[smiles_col].to_list()\n",
    "y_test = torch.tensor(test_df[target_col].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-section",
   "metadata": {},
   "source": [
    "## 5. Configure and Train MOE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# HYPERPARAMETERS - Adjust as needed\n",
    "# ============================================\n",
    "\n",
    "# Model architecture\n",
    "input_size = 768          # Embedding dimension (fixed)\n",
    "output_size = 2048        # Output dimension\n",
    "num_experts = 12          # Total number of experts\n",
    "k = 4                     # Number of experts to activate\n",
    "\n",
    "# Training settings\n",
    "batch_size = 32           # Increase if you have GPU memory\n",
    "learning_rate = 1e-4      # Lower for regression\n",
    "epochs = 150              # Train for more epochs\n",
    "\n",
    "# Regression output\n",
    "output_dim = 1            # Single target regression\n",
    "dropout = 0.2             # Dropout rate\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  - Batch size: {batch_size}\")\n",
    "print(f\"  - Learning rate: {learning_rate}\")\n",
    "print(f\"  - Epochs: {epochs}\")\n",
    "print(f\"  - Experts: {num_experts}, activating {k} per sample\")\n",
    "print(f\"  - Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init-moe",
   "metadata": {},
   "outputs": [],
   "source": "# Define experts (4 per modality)\nmodels = [\n    smi_ted, smi_ted, smi_ted, smi_ted,              # SMI-TED experts\n    model_selfies, model_selfies, model_selfies, model_selfies,  # SELFIES-TED experts\n    mhg_gnn, mhg_gnn, mhg_gnn, mhg_gnn                # MHG-GNN experts\n]\n\n# Initialize tokenizer with dynamic path\nvocab_path = EXPERTS_DIR / 'smi_ted_light' / 'bert_vocab_curated.txt'\nassert vocab_path.exists(), f\"Vocab file not found: {vocab_path}\"\ntokenizer = MolTranBertTokenizer(str(vocab_path))\n\n# Initialize MOE\nprint(\"Initializing MOE model...\")\nmoe_model = MoE(\n    input_size=input_size, \n    output_size=output_size, \n    num_experts=num_experts, \n    models=models, \n    tokenizer=tokenizer, \n    tok_emb=smi_ted.encoder.tok_emb, \n    k=k, \n    noisy_gating=True,      # Use noisy gating for better exploration\n    verbose=False\n).to(DEVICE)\n\n# Fix 1: Patch the EmbeddingNet to move tokens to device\n# This fixes the \"Expected all tensors to be on the same device\" error\ndef fixed_forward(self, smiles):\n    \"\"\"Patched forward that ensures tokens are on the correct device\"\"\"\n    tokens = self.tokenizer(smiles, padding=True, truncation=True, max_length=512, return_tensors='pt')\n    \n    # Move tokens to the same device as the model\n    device = next(self.parameters()).device\n    idx = tokens['input_ids'].to(device)\n    mask = tokens['attention_mask'].to(device)\n    \n    token_embeddings = self.tok_emb(idx)\n    input_mask_expanded = mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    return sum_embeddings / sum_mask\n\n# Apply the embedding patch\nmoe_model.embd_net.forward = lambda smiles: fixed_forward(moe_model.embd_net, smiles)\n\n# Fix 2: Patch SparseDispatcher.dispatch to use pure Python list operations\n# This fixes pandas/numpy indexing issues with CUDA tensors\nfrom moe import SparseDispatcher\n\n# Only patch if not already patched (prevents recursion if cell is run multiple times)\nif not hasattr(SparseDispatcher.dispatch, '_is_patched'):\n    _original_dispatch = SparseDispatcher.dispatch\n\n    def patched_dispatch(self, inp):\n        \"\"\"Patched dispatch using pure Python list operations (no pandas/numpy)\"\"\"\n        # Convert batch_index to Python list\n        if self._batch_index.is_cuda:\n            batch_index_list = self._batch_index.cpu().tolist()\n        else:\n            batch_index_list = self._batch_index.tolist()\n        \n        # Index into input list\n        inp_expanded = [inp[i] for i in batch_index_list]\n        \n        # Split into parts according to _part_sizes\n        result = []\n        start_idx = 0\n        for part_size in self._part_sizes:\n            result.append(inp_expanded[start_idx:start_idx + part_size])\n            start_idx += part_size\n        \n        return result\n\n    # Mark as patched and replace\n    patched_dispatch._is_patched = True\n    SparseDispatcher.dispatch = patched_dispatch\n    print(\"✓ SparseDispatcher.dispatch patched (pure Python list ops)\")\nelse:\n    print(\"✓ SparseDispatcher.dispatch already patched\")\n\n# Initialize predictor network\nnet = Net(smiles_embed_dim=output_size, dropout=dropout, output_dim=output_dim)\nnet.apply(smi_ted._init_weights)\nnet = net.to(DEVICE)\n\nprint(\"✓ Models initialized\")\nprint(\"✓ Device compatibility patches applied (EmbeddingNet + SparseDispatcher)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # Mean Squared Error for regression\n",
    "\n",
    "params = list(moe_model.parameters()) + list(net.parameters())\n",
    "optim = torch.optim.AdamW(params, lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, mode='min', factor=0.5, patience=10, verbose=True\n",
    ")\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    list(zip(X_train, y_train)), \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Training batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s67lviptc1s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PRE-TRAINING VALIDATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"Running pre-training validation checks...\\n\")\n",
    "\n",
    "# 1. GPU Check\n",
    "assert torch.cuda.is_available(), \"❌ CUDA not available!\"\n",
    "print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "gpu_mem_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "print(f\"  Memory: {gpu_mem_gb:.1f} GB\")\n",
    "\n",
    "# 2. Data Check\n",
    "assert data_file.exists(), f\"❌ Data file not found: {data_file}\"\n",
    "df_test = pd.read_csv(data_file, nrows=5)\n",
    "assert target_col in df_test.columns, f\"❌ Target column '{target_col}' not found\"\n",
    "full_dataset_size = len(pd.read_csv(data_file))\n",
    "print(f\"✓ Data file valid: {full_dataset_size} samples\")\n",
    "\n",
    "# 3. Model Check\n",
    "assert moe_model is not None, \"❌ MoE model not initialized\"\n",
    "assert net is not None, \"❌ Net model not initialized\"\n",
    "print(f\"✓ Models initialized and on device: {DEVICE}\")\n",
    "\n",
    "# 4. Disk Space Check\n",
    "import shutil\n",
    "disk_usage = shutil.disk_usage('.')\n",
    "free_gb = disk_usage.free / 1e9\n",
    "assert free_gb > 10, f\"❌ Low disk space: {free_gb:.1f} GB\"\n",
    "print(f\"✓ Disk space: {free_gb:.1f} GB free\")\n",
    "\n",
    "# 5. Memory Check (estimate)\n",
    "model_params = sum(p.numel() for p in moe_model.parameters()) + sum(p.numel() for p in net.parameters())\n",
    "print(f\"✓ Model parameters: {model_params/1e6:.1f}M\")\n",
    "\n",
    "# 6. Create checkpoint directory\n",
    "CHECKPOINT_DIR = NOTEBOOK_DIR / 'checkpoints'\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "print(f\"✓ Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All validation checks passed! Ready to train.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom training loop with validation\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    moe_model.train()\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for (x, y) in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        y = y.to(DEVICE)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        embd, aux_loss = moe_model(x)\n",
    "        y_hat = net(embd).squeeze()\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        total_loss = loss + aux_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)  # Gradient clipping\n",
    "        optim.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    moe_model.eval()\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_embd, _ = moe_model(X_valid, verbose=False)\n",
    "        valid_preds = net(valid_embd).squeeze()\n",
    "        valid_loss = loss_fn(valid_preds.cpu(), y_valid).item()\n",
    "    \n",
    "    valid_losses.append(valid_loss)\n",
    "    scheduler.step(valid_loss)\n",
    "    \n",
    "    # Save best model to checkpoint directory\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        checkpoint_path = CHECKPOINT_DIR / f'best_{model_name}_moe_model.pt'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'moe_state_dict': moe_model.state_dict(),\n",
    "            'net_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'valid_loss': valid_loss,\n",
    "        }, checkpoint_path)\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Valid Loss: {valid_loss:.4f}\")\n",
    "        print(f\"  Best Valid Loss: {best_valid_loss:.4f}\\n\")\n",
    "\n",
    "print(\"\\n✓ Training completed!\")\n",
    "print(f\"Best validation loss: {best_valid_loss:.4f}\")\n",
    "print(f\"Model saved to: {CHECKPOINT_DIR / f'best_{model_name}_moe_model.pt'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-losses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss', alpha=0.8)\n",
    "plt.plot(valid_losses, label='Validation Loss', alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title(f'Training History - {model_name}')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-section",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-best",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model from checkpoint directory\n",
    "checkpoint_path = CHECKPOINT_DIR / f'best_{model_name}_moe_model.pt'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "moe_model.load_state_dict(checkpoint['moe_state_dict'])\n",
    "net.load_state_dict(checkpoint['net_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Checkpoint: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "moe_model.eval()\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_embd, _ = moe_model(X_test, verbose=False)\n",
    "    test_preds = net(test_embd).squeeze()\n",
    "    test_preds_np = test_preds.cpu().numpy()\n",
    "    y_test_np = y_test.numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test_np, test_preds_np))\n",
    "mae = mean_absolute_error(y_test_np, test_preds_np)\n",
    "r2 = r2_score(y_test_np, test_preds_np)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"TEST SET RESULTS - {model_name}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-parity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(y_test_np, test_preds_np, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val = min(y_test_np.min(), test_preds_np.min())\n",
    "max_val = max(y_test_np.max(), test_preds_np.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect prediction')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel(f'Actual {target_col}', fontsize=12)\n",
    "ax.set_ylabel(f'Predicted {target_col}', fontsize=12)\n",
    "ax.set_title(f'Parity Plot - {model_name}\\nRMSE={rmse:.3f}, R²={r2:.3f}', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residuals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals plot\n",
    "residuals = y_test_np - test_preds_np\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residuals vs predicted\n",
    "axes[0].scatter(test_preds_np, residuals, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Predicted Values', fontsize=12)\n",
    "axes[0].set_ylabel('Residuals', fontsize=12)\n",
    "axes[0].set_title('Residuals vs Predicted', fontsize=12)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Residuals distribution\n",
    "axes[1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Residuals', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Distribution of Residuals', fontsize=12)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean of residuals: {residuals.mean():.4f}\")\n",
    "print(f\"Std of residuals: {residuals.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xgb-section",
   "metadata": {},
   "source": [
    "## 7. Train XGBoost on MOE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-embeddings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings for XGBoost\n",
    "print(\"Extracting embeddings...\")\n",
    "moe_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    xgb_train, _ = moe_model(X_train, verbose=False)\n",
    "    xgb_valid, _ = moe_model(X_valid, verbose=False)\n",
    "    xgb_test, _ = moe_model(X_test, verbose=False)\n",
    "\n",
    "xgb_train = xgb_train.cpu().numpy()\n",
    "xgb_valid = xgb_valid.cpu().numpy()\n",
    "xgb_test = xgb_test.cpu().numpy()\n",
    "\n",
    "y_train_np = y_train.numpy()\n",
    "y_valid_np = y_valid.numpy()\n",
    "\n",
    "print(f\"Train embeddings shape: {xgb_train.shape}\")\n",
    "print(f\"Valid embeddings shape: {xgb_valid.shape}\")\n",
    "print(f\"Test embeddings shape: {xgb_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-xgb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=50,\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    xgb_train, y_train_np,\n",
    "    eval_set=[(xgb_valid, y_valid_np)],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "print(\"\\n✓ XGBoost training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-xgb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost\n",
    "xgb_preds = xgb_model.predict(xgb_test)\n",
    "\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test_np, xgb_preds))\n",
    "xgb_mae = mean_absolute_error(y_test_np, xgb_preds)\n",
    "xgb_r2 = r2_score(y_test_np, xgb_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"XGBoost TEST SET RESULTS - {model_name}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE: {xgb_rmse:.4f}\")\n",
    "print(f\"MAE:  {xgb_mae:.4f}\")\n",
    "print(f\"R²:   {xgb_r2:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save XGBoost model to checkpoint directory\n",
    "xgb_model_path = CHECKPOINT_DIR / f'xgboost_{model_name}_model.json'\n",
    "xgb_model.save_model(str(xgb_model_path))\n",
    "print(f\"\\n✓ XGBoost model saved to: {xgb_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-xgb-parity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Parity plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ax.scatter(y_test_np, xgb_preds, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax.plot([y_test_np.min(), y_test_np.max()], [y_test_np.min(), y_test_np.max()], \n",
    "        'r--', linewidth=2, label='Perfect prediction')\n",
    "\n",
    "ax.set_xlabel(f'Actual {target_col}', fontsize=12)\n",
    "ax.set_ylabel(f'Predicted {target_col}', fontsize=12)\n",
    "ax.set_title(f'XGBoost Parity Plot - {model_name}\\nRMSE={xgb_rmse:.3f}, R²={xgb_r2:.3f}', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-section",
   "metadata": {},
   "source": [
    "## 8. Model Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both approaches\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['MOE + Net', 'MOE + XGBoost'],\n",
    "    'RMSE': [rmse, xgb_rmse],\n",
    "    'MAE': [mae, xgb_mae],\n",
    "    'R²': [r2, xgb_r2]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"FINAL COMPARISON - {model_name}\")\n",
    "print(\"=\"*60)\n",
    "print(comparison.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'R²']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    axes[idx].bar(comparison['Model'], comparison[metric], \n",
    "                  color=['steelblue', 'coral'], edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_ylabel(metric, fontsize=12)\n",
    "    axes[idx].set_title(f'{metric} Comparison', fontsize=12)\n",
    "    axes[idx].grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(comparison[metric]):\n",
    "        axes[idx].text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save comparison to checkpoint directory\n",
    "comparison_path = CHECKPOINT_DIR / f'comparison_{model_name}.csv'\n",
    "comparison.to_csv(comparison_path, index=False)\n",
    "print(f\"\\n✓ Comparison saved to: {comparison_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "predict-section",
   "metadata": {},
   "source": [
    "## 9. Make Predictions on New Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict-new",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Predict on new SMILES\n",
    "new_smiles = [\n",
    "    'CCO',  # Ethanol\n",
    "    'CC(=O)O',  # Acetic acid\n",
    "    'c1ccccc1',  # Benzene\n",
    "]\n",
    "\n",
    "# Normalize\n",
    "new_smiles_canon = [normalize_smiles(s) for s in new_smiles]\n",
    "\n",
    "# Predict using MOE+Net\n",
    "moe_model.eval()\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    new_embd, _ = moe_model(new_smiles_canon, verbose=False)\n",
    "    new_preds = net(new_embd).squeeze().cpu().numpy()\n",
    "\n",
    "# Predict using XGBoost\n",
    "xgb_new_preds = xgb_model.predict(new_embd.cpu().numpy())\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame({\n",
    "    'SMILES': new_smiles,\n",
    "    'MOE+Net Prediction': new_preds,\n",
    "    'XGBoost Prediction': xgb_new_preds\n",
    "})\n",
    "\n",
    "print(f\"\\nPredictions for {target_col}:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}